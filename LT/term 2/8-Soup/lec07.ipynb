{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711946b4-e12c-44a8-9d61-89a76886a7ea",
   "metadata": {},
   "source": [
    "## Скрейпинг и beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06371bca-5bfd-4702-a6a5-68c887e58267",
   "metadata": {},
   "source": [
    "Лингвисту, особенно компьютерному, часто бывает нужно добывать себе текстовые данные. Интернет - отличный источник таких данных, а программирование позволяет автоматизировать процесс их добычи, так что можно, например, самостоятельно собрать маленький корпус каких-нибудь текстов, взятых из интернета, и проводить на них исследования (карманный ГИКРЯ!). \n",
    "\n",
    "Конечно, большие корпуса, созданные по технологии Web as Corpus (Kilgariff), делать сложно, и нужно много всего знать для этого, но небольшой объем материала получить мы с вами вполне можем. \n",
    "\n",
    "Отличный источник текстов из интернета - это, конечно, Википедия. Википедия сама выкладывает в открытый доступ дампы для всех своих языков, их можно легко скачать (только они гигантские) [тут](https://dumps.wikimedia.org/). Есть и библиотеки для работы с этими дампами, например, ```pip install wiki-dump-reader```. Вот пример кода для него:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b094c-48e5-4e4c-a365-eca8a144c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiki_dump_reader import Cleaner, iterate\n",
    "\n",
    "path = input() # путь к вашему дампу\n",
    "cleaner = Cleaner()\n",
    "i = 0\n",
    "test = open('textwiki.txt', 'w', encoding='utf8') # откроем файл, куда будем записывать обработанный дамп\n",
    "for title, text in iterate(path): # title - заголовок статьи, text - ее текст\n",
    "    if i > 10:\n",
    "        break\n",
    "    text = cleaner.clean_text(text) # текст нужно почистить от всякой html-обвязки\n",
    "    cleaned_text, links = cleaner.build_links(text) # можно еще ссылки извлечь из текста\n",
    "    i += 1\n",
    "    print(f'text: {cleaned_text}\\n___\\nLinks: {links}', file=test)\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f3506-7c09-4449-b5ee-81be0406d306",
   "metadata": {},
   "source": [
    "Также вы самостоятельно осваивали библиотеку - API к Википедии. (```pip install wikipedia-api```). Комментировать подробно я тут не буду, к тому же, у этой библиотеки хорошая документация, просто приведу некоторые примеры из нее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e7ee5-c861-4994-be73-6baf123fac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91297fbc-b0a2-4832-98f0-4dc28b114492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем одиночную страницу\n",
    "wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "page_py = wiki_wiki.page('Python_(programming_language)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9a338-d7ba-4c95-a3af-22bab8afb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем, существует ли вообще такая:\n",
    "\n",
    "page_py = wiki_wiki.page('Python_(programming_language)')\n",
    "print(f\"Page - Exists: {page_py.exists()}\")\n",
    "# Page - Exists: True\n",
    "\n",
    "page_missing = wiki_wiki.page('NonExistingPageWithStrangeName')\n",
    "print(f\"Page - Exists: {page_missing.exists()}\")\n",
    "# Page - Exists: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd955043-c9c0-47cb-9b4e-c213605cb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим информацию о странице:\n",
    "print(page_py.title)\n",
    "print(page_py.summary[0:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3cc92-9d5f-49fa-8a7c-fb4e3c131078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как получать полный текст страницы:\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")\n",
    "\n",
    "p_wiki = wiki_wiki.page(\"Test 1\")\n",
    "print(p_wiki.text)\n",
    "\n",
    "\n",
    "wiki_html = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.HTML\n",
    ")\n",
    "p_html = wiki_html.page(\"Test 1\")\n",
    "print(p_html.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274feb50-3c86-4c57-ae00-f1a0f75e3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как получить отдельные секции страницы:\n",
    "\n",
    "def print_sections(sections, level=0):\n",
    "    for s in sections:\n",
    "        print(f\"{level + 1}: {s.title} - {s.text[0:40]}\")\n",
    "        print_sections(s.sections, level + 1)\n",
    "\n",
    "print_sections(page_py.sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1c390-457d-4a8b-985c-71649715dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как получить ссылки на эту же страницу на других языках:\n",
    "\n",
    "def print_langlinks(page):\n",
    "    langlinks = page.langlinks\n",
    "    for k in sorted(langlinks.keys()):\n",
    "        v = langlinks[k]\n",
    "        print(f\"{k}: {v.language} - {v.title}: {v.fullurl}\")\n",
    "\n",
    "print_langlinks(page_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20175b-192d-44b5-9b82-d2327c621a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как получить ссылки на странице:\n",
    "\n",
    "def print_links(page):\n",
    "    links = page.links\n",
    "    for title in sorted(links.keys()):\n",
    "        print(f\"{title}: {links[title]}\")\n",
    "\n",
    "print_links(page_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33788535-38b1-4ae4-99ab-0e3d504c67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как получить категории страницы:\n",
    "\n",
    "def print_categories(page):\n",
    "    categories = page.categories\n",
    "    for title in sorted(categories.keys()):\n",
    "        print(f\"{title}: {categories[title]}\")\n",
    "\n",
    "\n",
    "print(\"Categories\")\n",
    "print_categories(page_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d1287-9f8d-43c2-a941-09c1c77f1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# как получить все страницы в категории:\n",
    "\n",
    "def print_categorymembers(categorymembers, level=0, max_level=1):\n",
    "    for c in categorymembers.values():\n",
    "        print(f\"{level + 1}: {c.title} (ns: c.ns)\")\n",
    "        if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level:\n",
    "            print_categorymembers(c.categorymembers, level=level + 1, max_level=max_level)\n",
    "\n",
    "\n",
    "cat = wiki_wiki.page(\"Category:Physics\")\n",
    "print(\"Category members: Category:Physics\")\n",
    "print_categorymembers(cat.categorymembers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325191f-fea7-485d-81e5-5ffe6d09619c",
   "metadata": {},
   "source": [
    "Наконец, в питоне есть встроенная библиотека urllib, которая позволяет обращаться к любым страницам в интернете и добывать их содержимое (даже точнее, ее подмодуль urllib.request). Самый простой способ с ее помощью прочитать содержимое страницы выглядит так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cc253-1f82-4f0a-be58-5f49c83ba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "with urllib.request.urlopen('http://python.org/') as response:\n",
    "    html = response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c753025-c818-4f27-87fe-da018752d2af",
   "metadata": {},
   "source": [
    "Выглядеть, правда, считанное будет страшновато:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98738621-8930-4ec8-be5c-8ec38e43963c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!doctype html>\\n<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\\n<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\\n<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\\n<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\\n\\n<head>\\n    <!-- Google tag (gtag.js) -->\\n    <script async src=\"https://www.googletagmanager.com/gtag/js?id=G-TF35YF9CVH\"></script>\\n    <script>\\n      window.d'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514ff84-6722-41e4-b113-0d15fdeb9ebd",
   "metadata": {},
   "source": [
    "Собственно говоря, тут неплохо вспомнить, что в интернете почти все страницы на самом деле написаны в каком-нибудь html. Язык разметки html (иногда его называют языком программирования, но это спорный вопрос, многие программисты будут с пеной у рта доказывать, что НЕТ) довольно просто устроен, в основном у него есть теги, которые берутся в треугольные скобки. В большинстве теги должны открываться и закрываться. Один из самых простых тегов, например, тег для курсива: ```<i> что-то, написанное курсивом </i>```. Другой тег (одиночный) - для переноса на новую строку: ```</br>```. (Кстати, тетрадки юпитера умеют в html...)\n",
    "\n",
    "И вот где-то там, посреди html-ного мусора, зарыты наши с вами тексты, которые мы и хотим добыть..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b08d1ba-5d45-45b8-b6ac-da9f8ede94be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'h-icon-72x72-precomposed.png\">\\n    <link rel=\"apple-touch-icon-precomposed\" href=\"/static/apple-touch-icon-precomposed.png\">\\n    <link rel=\"apple-touch-icon\" href=\"/static/apple-touch-icon-precomposed.png\">\\n\\n    \\n    <meta name=\"msapplication-TileImage\" content=\"/static/metro-icon-144x144-precomposed.png\"><!-- white shape -->\\n    <meta name=\"msapplication-TileColor\" content=\"#3673a5\"><!-- python blue -->\\n    <meta name=\"msapplication-navbutton-color\" content=\"#3673a5\">\\n\\n    <title>Welcome to Python.org</title>\\n\\n    <meta name=\"description\" content=\"The official home of the Python Programming Language\">\\n    <meta name=\"keywords\" content=\"Python programming language object oriented web free open source software license documentation download community\">\\n\\n    \\n    <meta property=\"og:type\" content=\"website\">\\n    <meta property=\"og:site_name\" content=\"Python.org\">\\n    <meta property=\"og:title\" content=\"Welcome to Python.org\">\\n    <meta property=\"og:description\" content=\"The official home of'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[3000:4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4dab4-6f0e-4030-80c0-4bd2e099acc3",
   "metadata": {},
   "source": [
    "Как же их достать оттуда? Можно, конечно, регулярными выражениями: но это долго и муторно, и для каждой страницы регулярные выражения могут понадобиться свои. Ну, и поскольку эта задача частая и хорошо известная, разумеется, для нее написаны специальные библиотеки. \n",
    "\n",
    "Самая известная такая библиотека - beautifulsoup4. Вообще у этой библиотеки тоже очень хорошая подробная [документация](https://www.crummy.com/software/BeautifulSoup/), но какие-то основные штуки мы с вами сейчас посмотрим. \n",
    "\n",
    "Устанавливается как \n",
    "\n",
    "    pip install beautifulsoup4\n",
    "    \n",
    "Вероятно, в жизни вам еще понадобятся дополнительные библиотеки:\n",
    "\n",
    "    pip install lxml\n",
    "    pip install html5lib\n",
    "    \n",
    "(если вдруг вам надо будет извлекать текст из этих форматов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73fe06-2740-483d-a7fc-c92cdf56acf3",
   "metadata": {},
   "source": [
    "Основной класс библиотеки bs4 - это так называемый суп (BeautifulSoup). Когда мы хотим распарсить какую-то html-страницу, нужно ее содержимое в него передать. Давайте передадим нашу страницу с сайта питона:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861dfe25-c62a-4a3d-aa8c-98e839cd03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3190f1e-83d5-49de-8fcf-c1c6ae36884f",
   "metadata": {},
   "source": [
    "Вот теперь с нашим супом можно сделать все, что угодно. Например, можно извлечь заголовок страницы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e4ef7c5-3293-405b-a2b3-6347e036868f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Welcome to Python.org</title>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d378dfd-2ae1-4c88-a5a8-089de5534deb",
   "metadata": {},
   "source": [
    "Как правило, почти у любого объекта внутри супа есть атрибут text, который позволяет добыть сам текст без html-тегов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee91faf8-2206-4ee8-a617-581ab05969f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to Python.org'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6fd4e-9c03-4f86-b15a-05308865f261",
   "metadata": {},
   "source": [
    "Частая задача - найти все ссылки на нашей странице. Это можно сделать таким образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c5c01-6621-46d4-a4cf-3d8719394a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e6f6c-736e-4ea9-bedb-5f7b7c65fe47",
   "metadata": {},
   "source": [
    "Там могут быть как полные ссылки на внешние страницы, так и относительные: обычно если ссылка начинается на /, это значит, что к ней спереди нужно добавить исходный адрес страницы. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fee958-d5a5-4fd0-889c-a81ada33c450",
   "metadata": {},
   "source": [
    "Вообще прежде чем что-нибудь еще вытаскивать из документа, давайте прикинем, какая у нашего html структура. \n",
    "\n",
    "<img src=\"https://itchief.ru/assets/images/javascript/dom/tree.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22abb1-8a97-4a24-b4d1-4245cbee5646",
   "metadata": {},
   "source": [
    "Примерно так (кстати, картинка вставлена html-кодом :)). На самом деле внутри body могут быть какие угодно штуки, могут быть ```<div>``` (типа сегменты), например. К любому из этих тегов можно обратиться через soup. Например, выше, когда мы написали ```soup.title```, мы ровно это и сделали! \n",
    "\n",
    "Окей, заголовок документа и его тело (body) явно присутствуют в одиночном экземпляре, но как быть с разнообразными ```<div>```, которых может быть больше одного? Если мы напишем просто ```soup.div```, мы обратимся к первому встретившемуся такому тегу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efd43f-3bcc-49e8-9e6d-7f7f4a18b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb69eec-2b62-4e64-b814-99d2c14bccf5",
   "metadata": {},
   "source": [
    "(Там был очень длинный div, поэтому я почистила аутпут ячейки). \n",
    "\n",
    "Давайте возьмем что-нибудь покороче:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3f666ad-7e5a-4adb-afc3-9d4543b30fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"#content\" title=\"Skip to content\">Skip to content</a>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502188b7-8cbe-4e36-9e90-50bdda450afd",
   "metadata": {},
   "source": [
    "Это самая первая ссылка на странице. На самом деле ```soup.a``` - это специальный объект класса Tag, у которого тоже есть всякие свои штуки, которые мы можем посмотреть. Например, у тега есть имя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44f0d0ec-e832-4205-8791-6938f62a8dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea44f53-16e6-47eb-83e9-45a230c38bad",
   "metadata": {},
   "source": [
    "(Довольно очевидное...)\n",
    "\n",
    "Еще у него могут быть атрибуты, к которым можно обращаться, как к ключам словаря. У нашей ссылки есть title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29772259-b632-4758-a04f-ec480a70d5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skip to content'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e42cb-5a16-427b-ae72-be05c3e2db94",
   "metadata": {},
   "source": [
    "Атрибуты можно добавлять, удалять и изменять (но для задач добывания текста из html-страницы нам это не особо нужно). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6d84f-78c7-49a1-9dbc-0fa212e51c3c",
   "metadata": {},
   "source": [
    "Добыть все теги с одинаковым именем в нашем супе мы уже пробовали, для этого есть метод find_all. При этом может понадобиться проверять, какие атрибуты есть у наших тегов. Для этого есть метод has_attr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f50702b5-9c20-4f18-9cc6-d7fafbd6a2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do-not-print']\n",
      "['top-bar', 'do-not-print']\n",
      "['skip-link', 'screen-reader-text']\n",
      "['container']\n",
      "['options-bar-container', 'do-not-print']\n",
      "['options-bar']\n",
      "['adjust-font-size']\n",
      "['winkwink-nudgenudge']\n",
      "['header-banner']\n",
      "['flex-slideshow', 'slideshow']\n",
      "['slide-code']\n",
      "['slide-copy']\n",
      "['slide-code']\n",
      "['slide-copy']\n",
      "['slide-code']\n",
      "['slide-copy']\n",
      "['slide-code']\n",
      "['slide-copy']\n",
      "['slide-code']\n",
      "['slide-copy']\n",
      "['introduction']\n",
      "['content-wrapper']\n",
      "['container']\n",
      "['row']\n",
      "['small-widget', 'get-started-widget']\n",
      "['small-widget', 'download-widget']\n",
      "['small-widget', 'documentation-widget']\n",
      "['small-widget', 'jobs-widget', 'last']\n",
      "['list-widgets', 'row']\n",
      "['medium-widget', 'blog-widget']\n",
      "['shrubbery']\n",
      "['medium-widget', 'event-widget', 'last']\n",
      "['shrubbery']\n",
      "['row']\n",
      "['medium-widget', 'success-stories-widget']\n",
      "['shrubbery']\n",
      "['success-story-item']\n",
      "['medium-widget', 'applications-widget', 'last']\n",
      "['shrubbery']\n",
      "['pep-widget']\n",
      "['psf-widget']\n",
      "['python-logo']\n",
      "['main-footer-links']\n",
      "['container']\n",
      "['site-base']\n",
      "['container']\n",
      "['copyright']\n"
     ]
    }
   ],
   "source": [
    "for div in soup.find_all('div'):\n",
    "    if div.has_attr('class'):\n",
    "        print(div['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324aa44-a1d2-48d8-8ccb-fee3bbf3ca9e",
   "metadata": {},
   "source": [
    "Ну и самая важная для нас штука, которая позволит извлечь из тега человекочитаемый текст: get_text(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f719f9d-74b6-473e-8d8b-75978fa4cc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Notice: While JavaScript is not essential for this website, your interaction with the content will\n",
      " Notice: While JavaScript is not essential for this website, your interaction with the content will \n",
      "   Skip to content   ▼ Close                    Python   PSF   Docs   PyPI   Jobs   Community    ▲ T\n",
      " Skip to content \n",
      "     Donate  ≡ Menu   Search This Site                                       GO                     \n"
     ]
    }
   ],
   "source": [
    "for idx, div in enumerate(soup.find_all('div')): # пронумерую просто для того, чтобы не выводить вообще все\n",
    "    if idx >= 5:\n",
    "        break\n",
    "    print(div.get_text()[:100].replace('\\n', ' ')) # навешаю всякого, чтобы не выводить полный текст и убрать лишние переносы строк"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86f336-d331-4eba-b9ce-8d369460eee4",
   "metadata": {},
   "source": [
    "Что на самом деле делает этот метод - он берет все кусочки человеческого текста в коде и склеивает их, как ему кажется правильным. Мы можем достать эти кусочки самостоятельно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ad6dc4a-1526-47c8-8a44-537559e0ab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to Python.org Notice: While JavaScript is not essential for this website, your interaction with the content will be limited. Please turn JavaScript on for the full experience. Skip to content ▼ Close Python PSF Docs PyPI Jobs Community ▲ The Python Network Donate ≡ Menu Search This Site GO A A Smaller Larger Reset Socialize Facebook Twitter Chat on IRC About Applications Quotes Getting Started Help Python Brochure Downloads All releases Source code Windows macOS Other Platforms License Alternative Implementations Documentation Docs Audio/Visual Talks Beginner\\'s Guide Developer\\'s Guide FAQ Non-English Docs PEP Index Python Books Python Essays Community Diversity Mailing Lists IRC Forums PSF Annual Impact Report Python Conferences Special Interest Groups Python Logo Python Wiki Code of Conduct Community Awards Get Involved Shared Stories Success Stories Arts Business Education Engineering Government Scientific Software Development News Python News PSF Newsletter PSF News PyCon US News News from the Community Events Python Events User Group Events Python Events Archive User Group Events Archive Submit an Event >_ Launch Interactive Shell # Python 3: Fibonacci series up to n >>> def fib(n):\\r\\n>>>     a, b = 0, 1\\r\\n>>>     while a < n:\\r\\n>>>         print(a, end=\\' \\')\\r\\n>>>         a, b = b, a+b\\r\\n>>>     print()\\r\\n>>> fib(1000) 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 Functions Defined The core of extensible programming is defining functions. Python allows mandatory and optional arguments, keyword arguments, and even arbitrary argument lists. More about defining functions in Python\\xa03 # Python 3: List comprehensions >>> fruits = [\\'Banana\\', \\'Apple\\', \\'Lime\\']\\r\\n>>> loud_fruits = [fruit.upper() for fruit in fruits]\\r\\n>>> print(loud_fruits) [\\'BANANA\\', \\'APPLE\\', \\'LIME\\'] # List and the enumerate function >>> list(enumerate(fruits)) [(0, \\'Banana\\'), (1, \\'Apple\\'), (2, \\'Lime\\')] Compound Data Types Lists (known as arrays in other languages) are one of the compound data types that Python understands. Lists can be indexed, sliced and manipulated with other built-in functions. More about lists in Python\\xa03 # Python 3: Simple arithmetic >>> 1 / 2 0.5 >>> 2 ** 3 8 >>> 17 / 3 # classic division returns a float 5.666666666666667 >>> 17 // 3 # floor division 5 Intuitive Interpretation Calculations are simple with Python, and expression syntax is straightforward: the operators + , - , * and / work as expected; parentheses () can be used for grouping. More about simple math functions in Python\\xa03 . # For loop on a list >>> numbers = [2, 4, 6, 8]\\r\\n>>> product = 1\\r\\n>>> for number in numbers:\\r\\n...    product = product * number\\r\\n... \\r\\n>>> print(\\'The product is:\\', product) The product is: 384 All the Flow You’d Expect Python knows the usual control flow statements that other languages speak — if , for , while and range — with some of its own twists, of course. More control flow tools in Python\\xa03 # Simple output (with Unicode) >>> print(\"Hello, I\\'m Python!\") Hello, I\\'m Python! # Input, assignment >>> name = input(\\'What is your name?\\\\n\\') What is your name?\\r\\nPython >>> print(f\\'Hi, {name}.\\') Hi, Python. Quick & Easy to Learn Experienced programmers in any other language can pick up Python very quickly, and beginners find the clean syntax and indentation structure easy to learn. Whet your appetite with our Python\\xa03 overview. Python is a programming language that lets you work quickly and integrate systems more effectively. Learn More Get Started Whether you\\'re new to programming or an experienced developer, it\\'s easy to learn and use Python. Start with our Beginner’s Guide Download Python source code and installers are available for download for all versions! Latest: Python 3.12.0 Docs Documentation for Python\\'s standard library, along with tutorials and guides, are available online. docs.python.org Jobs Looking for work or have a Python related position that you\\'re trying to hire for? Our relaunched community-run job board is the place to go. jobs.python.org Latest News More 2023- 10-13 Python 3.13.0 alpha 1 is now available 2023- 10-02 Python 3.11.6 is now available 2023- 10-02 Python 3.12.0 (final) now available 2023- 09-27 Python Developers Survey Numbers for 2022! 2023- 09-19 Python 3.12.0 release candidate 3 now available Upcoming Events More 2023- 10-18 The When of Python, and Dependency Injection Principle 2023- 10-21 EduPy 2023 2023- 10-21 PyDay Cali 2023 2023- 10-22 TOUFU - Parent-Child Python Programming Workshop 2023- 10-26 PackagingCon 2023 Success Stories More Generating realistic location data for users for testing or modeling simulations is a hard problem. Current approaches just create random locations inside a box, placing users in waterways or on top of buildings. This inability to make accurate, synthetic location data stifles a lot of innovative projects that require diverse and complex datasets to fuel their work. Using Python with Gretel.ai to Generate Synthetic Location Data by Alex Watson, co-founder and CPO, Gretel.ai Use Python for… More Web Development : Django , Pyramid , Bottle , Tornado , Flask , web2py GUI Development : tkInter , PyGObject , PyQt , PySide , Kivy , wxPython Scientific and Numeric : SciPy , Pandas , IPython Software Development : Buildbot , Trac , Roundup System Administration : Ansible , Salt , OpenStack , xonsh >>> Python Enhancement Proposals (PEPs) : The future of Python is discussed here. RSS >>> Python Software Foundation The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers. Learn more Become a Member Donate to the PSF ▲ Back to Top About Applications Quotes Getting Started Help Python Brochure Downloads All releases Source code Windows macOS Other Platforms License Alternative Implementations Documentation Docs Audio/Visual Talks Beginner\\'s Guide Developer\\'s Guide FAQ Non-English Docs PEP Index Python Books Python Essays Community Diversity Mailing Lists IRC Forums PSF Annual Impact Report Python Conferences Special Interest Groups Python Logo Python Wiki Code of Conduct Community Awards Get Involved Shared Stories Success Stories Arts Business Education Engineering Government Scientific Software Development News Python News PSF Newsletter PSF News PyCon US News News from the Community Events Python Events User Group Events Python Events Archive User Group Events Archive Submit an Event Contributing Developer\\'s Guide Issue Tracker python-dev list Core Mentorship Report a Security Issue ▲ Back to Top Help & General Contact Diversity Initiatives Submit Website Bug Status Copyright ©2001-2023. Python Software Foundation Legal Statements Privacy Policy'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([text for text in soup.stripped_strings]) # stripped_strings достанет все человекочитаемые кусочки текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a087c4d-ccfc-4bcf-83c6-b5249fa72d98",
   "metadata": {},
   "source": [
    "Это, разумеется, не все возможности библиотеки, но для начала работы с ней хватит. Все подробности можно найти в их документации. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
