{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1: Частотный анализ текста  \n",
    "Реализуйте класс TextAnalyzer, который анализирует текстовый файл и предоставляет следующие возможности:  \n",
    "- Подсчёт частоты слов. (заранее лемматизировать. здесь поможет библиотека, например, pymorphy2)  \n",
    "- Вывод топ-10 самых частых слов.  \n",
    "- Вывод контекста (по запросу должны выводиться 3 любых предложения, в которых слово употребляется)\n",
    "- Подсчёт распределения частей речи.\n",
    "- Сохранение результатов в файл.  \n",
    "\n",
    "Программа должна работать с файлом text.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример использования:  \n",
    "# analyzer = TextAnalyzer(\"text.txt\")\n",
    "# analyzer.process_text()\n",
    "# analyzer.print_statistics()\n",
    "# analyzer.save_results(\"word_frequencies.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## пример вывода:\n",
    "\n",
    "10 самых частотных слов: \n",
    "\n",
    "1. слово1\n",
    "2. слово2\n",
    "...\n",
    "\n",
    "частотность частей речи:\n",
    "1. часть речи 1: x%\n",
    "2. часть речи 2: n%\n",
    "...\n",
    "\n",
    "использование слова x:\n",
    "1. предложение1 со словом x\n",
    "2. предложение2 со словом x\n",
    "3. предложение3 со словом x\n",
    "\n",
    "\n",
    "\n",
    "формат записи в файл (по убыванию):\n",
    "\n",
    "слово1 (часть речи): n раз\n",
    "\n",
    "слово2 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2: Генерация N-грамм\n",
    "Реализуйте класс NGramAnalyzer, который выполняет анализ последовательностей слов.  \n",
    "Класс должен:   \n",
    "- Подсчитывать частоту n-грамм.  \n",
    "- У пользователя должна быть возможность задавать длину n-грамм.\n",
    "- Сохранять результаты в файл.  \n",
    "\n",
    "Программа должна работать с файлом text.txt.  \n",
    "\n",
    "Дополнительно:\n",
    "- Программа должна игнорировать стоп-слова (предлоги, союзы, местоимения)\n",
    "- Генерация n-грамм должна происходить без использования библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример использования:  \n",
    "# ngram_analyzer = NGramAnalyzer(\"text.txt\")\n",
    "# ngram_analyzer.process_text()\n",
    "# ngram_analyzer.print_top_ngrams()\n",
    "# ngram_analyzer.save_results(\"ngrams.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## пример вывода:\n",
    "\n",
    "10 самых частотных биграмм (по убыванию): \n",
    "\n",
    "1. биграмма1\n",
    "2. биграмма2\n",
    "...\n",
    "\n",
    "\n",
    "формат записи в файл (по убыванию):\n",
    "\n",
    "биграммы:\n",
    "\n",
    "    биграмма1 (часть речи 1 слова, часть речи 2 слова): n раз\n",
    "\n",
    "    биграмма2 \n",
    "\n",
    "    ...\n",
    "\n",
    "    биграмма n\n",
    "\n",
    "триграммы:\n",
    "\n",
    "\n",
    "    триграмма1 (часть речи 1 слова, часть речи 2 слова): n раз\n",
    "\n",
    "    триграмма2 \n",
    "\n",
    "    ...\n",
    "\n",
    "    триграмма n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3: Оценка читаемости текста  \n",
    "Реализуйте класс ReadabilityAnalyzer, который анализирует сложность текста по индексу Флеша-Кинкейда.  \n",
    "Класс должен:  \n",
    "- Подсчитывать количество предложений, слов и слогов.  \n",
    "- Вычислять индекс читаемости.  \n",
    "- Выдавать оценку уровня сложности текста.  \n",
    "- Сохранять результаты в файл.  \n",
    "\n",
    "Программа должна работать с файлом text.txt.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула для расчёта индекса Флеша-Кинкейда:\n",
    "\n",
    "$$\n",
    "FK = 206.835 - 1.52 \\times \\left(\\frac{\\text{число слов}}{\\text{число предложений}}\\right) - 65.14 \\times \\left(\\frac{\\text{число слогов}}{\\text{число слов}}\\right)\n",
    "$$\n",
    "\n",
    "### Пояснение переменных:\n",
    "- Число слов — общее количество слов в тексте.\n",
    "- Число предложений — общее количество предложений.\n",
    "- Число слогов — количество слогов во всех словах текста.\n",
    "\n",
    "### Интерпретация результатов:\n",
    "- 90–100 — Очень легко (для младших школьников).\n",
    "- 60–70 — Средняя сложность (понятно старшеклассникам).\n",
    "- 0–30 — Очень сложно (академический уровень)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример использования:  \n",
    "# readability = ReadabilityAnalyzer(\"text.txt\")\n",
    "# readability.process_text()\n",
    "# readability.print_readability_score()\n",
    "# readability.save_results(\"readability.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## пример вывода:\n",
    "индекс читаемости: n \n",
    "\n",
    "оценка читаемости: очень легко\n",
    "\n",
    "формат записи в файл:\n",
    "\n",
    "    число слов: n\n",
    "\n",
    "    число предложений: n\n",
    "\n",
    "    число слогов: n\n",
    "\n",
    "    индекс читаемости: n \n",
    "\n",
    "    оценка читаемости: очень легко\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
